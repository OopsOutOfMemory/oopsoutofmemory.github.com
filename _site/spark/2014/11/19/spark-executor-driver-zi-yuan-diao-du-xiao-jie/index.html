<!DOCTYPE html>
<html>
	<head>
	
	<link href="//gmpg.org/xfn/11" rel="profile">
	<meta http-equiv="content-type" content="text/html; charset=utf-8">
	<link rel="canonical" href="http://oopsoutofmemory.github.io/spark/2014/11/19/spark-executor-driver-zi-yuan-diao-du-xiao-jie" />
	<meta name="description" content="## 一、引子 在Worker Actor中，每次LaunchExecutor会创建一个CoarseGrainedExecutorBackend进程，Executor和CoarseGrainedExecutorBackend是1对1的关系。也就是说集群里启动多少Executor实例就有多少CoarseGrainedExecutorBackend进程。 那么到底是如何分配Executor的呢？怎么控制调节Executor的个数呢？ ## 二、Driver和Executor资源调度 下面主要介绍一下Spark Executor分配策略： 我们仅看，当Application提交注册到Master后，Master会返回RegisteredApplication，之后便会调用schedule（）这个方法，来分配Driver的资源，和启动Executor的资源。 schedule()方法是来调度当前可用资源的调度方法，它管理还在排队等待的Apps资源的分配，这个方法是每次在集群资源发生变动的时候都会调用，根据当前集群最新的资源来进行Apps的资源分配。 __Driver资源调度：__ 随机的将Driver分配到空闲的Worker上去，详细流程请看我写的注释 ：） ```scala // First schedule drivers, they..." />
	<meta property="og:description" content="## 一、引子 在Worker Actor中，每次LaunchExecutor会创建一个CoarseGrainedExecutorBackend进程，Executor和CoarseGrainedExecutorBackend是1对1的关系。也就是说集群里启动多少Executor实例就有多少CoarseGrainedExecutorBackend进程。 那么到底是如何分配Executor的呢？怎么控制调节Executor的个数呢？ ## 二、Driver和Executor资源调度 下面主要介绍一下Spark Executor分配策略： 我们仅看，当Application提交注册到Master后，Master会返回RegisteredApplication，之后便会调用schedule（）这个方法，来分配Driver的资源，和启动Executor的资源。 schedule()方法是来调度当前可用资源的调度方法，它管理还在排队等待的Apps资源的分配，这个方法是每次在集群资源发生变动的时候都会调用，根据当前集群最新的资源来进行Apps的资源分配。 __Driver资源调度：__ 随机的将Driver分配到空闲的Worker上去，详细流程请看我写的注释 ：） ```scala // First schedule drivers, they..." />
	<meta itemprop="image" content="http://oopsoutofmemory.github.io/assets/images/oopsoutofmemory.jpg" />
	<meta property="og:image" content="http://oopsoutofmemory.github.io/assets/images/oopsoutofmemory.jpg" />
	<meta property="og:title" content="Spark Executor Driver资源调度小结" />
	<meta property="og:type" content="article" />
	<meta property="og:url" content="http://oopsoutofmemory.github.io/spark/2014/11/19/spark-executor-driver-zi-yuan-diao-du-xiao-jie" />
	<meta property="og:site_name" content="盛利的博客" />
	<title>Spark Executor Driver资源调度小结 &middot; 盛利的博客</title>
	<meta name="mobile-web-app-capable" content="yes">
	<meta name="HandheldFriendly" content="True" />
	<meta name="MobileOptimized" content="320" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0" />
	<link rel="stylesheet" type="text/css" media="only screen and (min-width: 900px)" href="/assets/css/desktop.css" />
	<link rel="stylesheet" type="text/css" media="only screen and (max-width: 899px)" href="/assets/css/mobile.css" />
	<link href="/assets/css/genericons.css" type="text/css" rel="stylesheet" />
	<link href="/assets/css/index.css" type="text/css" rel="stylesheet" />
	<link href="/assets/css/syntax.css" type="text/css" rel="stylesheet" />
		<link href="/assets/css/style.css" type="text/css" rel="stylesheet" />
	<link rel="apple-touch-icon" href="http://oopsoutofmemory.github.io/assets/images/oopsoutofmemory.jpg">
	<link rel="shortcut icon" href="http://oopsoutofmemory.github.io/assets/images/favicon.ico">
	<link rel="alternate" type="application/rss+xml" title="RSS" href="http://oopsoutofmemory.github.io/atom.xml">
	<script type="text/javascript" src="/assets/js/jquery-2.1.0.min.js"></script>
	<script type="text/javascript" src="/assets/js/jquery.stellar.min.js"></script>
	<script type="text/javascript" src="/assets/js/rocket.js"></script>
	<script type="text/javascript" src="/assets/js/jekyll-search.js"></script>
	
</head>

	<body>
		<header class="clean" style="background-image: url(/assets/images/cover.jpg); height: 100%;" data-stellar-background-ratio="0.5" data-stellar-horizontal-offset="50">
	
	<span id="home-intro">
	<b>OopsOutOfMemory 盛利's Blog</b><br/>
    <span class="desc"><b>专注大数据领域，分布式计算，Spark Contributor</b></span>
</span>
<label class="menu" for="_1">
	<span class="genericon genericon-menu"></span>
	
</label>
<input id="_1" type="checkbox">
<div class="menu-content">
	<p class="menu-title">盛利的博客<p>
	<div class="menu" style="background-color: #1a1a1a; z-index: -1;"></div>
	
		<a href="/">首页</a>
	
		<a href="/category.html">博客列表</a>
	
		<a href="/aboutMe.html">关于我</a>
	
		<a href="/404">Test 404</a>
	
	<hr>
	
</div>
 <div  class="social-links" data-stellar-ratio="0.1" style="-webkit-transform: translate3d(0px, 0px, 0px);">
		
<div id="search-container" >
      <input type="text" id="search-input" placeholder="search...">
      <ul id="results-container" style="position: absolute;"></ul>
 </div>
		<a href="http://oopsoutofmemory.github.io"  title="Home" ><span style="display: inline-block;font-size: 45px;position: relative;top: -4px;
right: 10px;" class="genericon genericon-home"  >
			</span></a>

			<a href="http://weibo.com/oopsoom" target="_blank" title="Sina WeiBo" ><img class="genericon genericon-github" src="/assets/images/icon/weibo.png" style="width:35px; height:32px;">
			</img></a>

			<a href="https://github.com/OopsOutOfMemory" target="_blank" title="Fork me on github"><img class="genericon genericon-github" src="/assets/images/icon/github.jpg" style="width:32px; height:29px;">
			</img></a>
		
			<a href="https://twitter.com/sheng_victor" target="_blank" title="Follow me on twitter"><img class="genericon genericon-github" src="/assets/images/icon/twitter.png" style="width:34px; height:30px;">
			</img></a>
		
			<a target="_blank" href="http://shang.qq.com/wpa/qunwpa?idkey=e5179e72fd9f500ad852aefa6e2824dc2fb59868de8fa3d5b65eae670a2fc437"><img class="genericon genericon-github" src="/assets/images/icon/qqqun.png" alt="Spark Ecosystem技术交流" style="width:34px; height:30px;" title="Spark Ecosystem技术交流"></a>
		
	</div>

<div class="social-links" data-stellar-ratio="0.1">
	
</div>

	<div style="display: none;" id="rocket-to-top">
	<div style="opacity:0;display: block;" class="level-2"></div>
	<div class="level-3"></div>
	</div>
 <script type="text/javascript">
      SimpleJekyllSearch.init({
        searchInput: document.getElementById('search-input'),
        resultsContainer: document.getElementById('results-container'),
        dataSource: '/search.json',
        searchResultTemplate: '<li><a href="{url}" title="{desc}">{title}</a></li>',
        noResultsText: 'No results found',
        limit: 10,
        fuzzy: false,
      })
    </script>


	<div id="post-info" data-stellar-ratio="0.7">
		<a class="site-title" style="font-weight:red"><原创文章></a>
		<h1><span style="left:12px; backgroun-color: ;color:darkblue; top:-7px;" class="yuanchuang">原</span>
Spark Executor Driver资源调度小结</h1>
		
		<a class="site-title" style="display: inline-block;padding-left: 20px;" href="http://oopsoutofmemory.github.io"><div class="site-icon-small" style="background-image: url(/assets/images/oopsoutofmemory.jpg);"></div>盛利的博客</a>, in 19 November 2014

	</div>

	<div id="nav-icon" style="bottom: 30px;" data-stellar-ratio="4">
		<a class="scroll" data-speed="500" href="#article"><span class="genericon genericon-expand"></span></a>
	</div>
</header>

<div id="middle">

	<div class="nav">
	<div class="title"><span style="padding-right: 10px;" class="genericon genericon-menu"><a style="color:white;" href="/category.html"><span>&nbsp;&nbsp;&nbsp;Category</span></a></div>
	 
	<a  href="/category.html#spark" title="view all posts">
		<span style="padding-right: 10px;" class="genericon genericon-pinned"></span>
		Spark <span class="bubble">4</span></a>
	 
	<a  href="/category.html#scala" title="view all posts">
		<span style="padding-right: 10px;" class="genericon genericon-pinned"></span>
		Scala <span class="bubble">6</span></a>
	 
	<a  href="/category.html#machine learning" title="view all posts">
		<span style="padding-right: 10px;" class="genericon genericon-pinned"></span>
		Machine learning <span class="bubble">3</span></a>
	 
	<a  href="/category.html#hadoop" title="view all posts">
		<span style="padding-right: 10px;" class="genericon genericon-pinned"></span>
		Hadoop <span class="bubble">1</span></a>
	 
	<a  href="/category.html#hive" title="view all posts">
		<span style="padding-right: 10px;" class="genericon genericon-pinned"></span>
		Hive <span class="bubble">7</span></a>
	 
	<a  href="/category.html#mllib" title="view all posts">
		<span style="padding-right: 10px;" class="genericon genericon-pinned"></span>
		Mllib <span class="bubble">1</span></a>
	 
	<a  href="/category.html#life" title="view all posts">
		<span style="padding-right: 10px;" class="genericon genericon-pinned"></span>
		Life <span class="bubble">1</span></a>
	 
	<a class="" href="/category.html"><span style="padding-right: 12px;" class="genericon genericon-pinned"></span>Show All</a>



	<div class="nav" style="margin: 0;margin-top: 20px; min-height: 0;">
		<div class="title"><span style="padding-right: 10px;" class="genericon genericon-menu"></span>友情链接</div>
		<a target="_blank" href="http://fy98.com/">Frank Fan's Blog</a>
	</div>
</div>


	
	<div id="article">
		<h2>一、引子</h2>

<p>在Worker Actor中，每次LaunchExecutor会创建一个CoarseGrainedExecutorBackend进程，Executor和CoarseGrainedExecutorBackend是1对1的关系。也就是说集群里启动多少Executor实例就有多少CoarseGrainedExecutorBackend进程。
  那么到底是如何分配Executor的呢？怎么控制调节Executor的个数呢？</p>

<h2>二、Driver和Executor资源调度</h2>

<p>下面主要介绍一下Spark Executor分配策略：</p>

<p>我们仅看，当Application提交注册到Master后，Master会返回RegisteredApplication，之后便会调用schedule（）这个方法，来分配Driver的资源，和启动Executor的资源。
schedule()方法是来调度当前可用资源的调度方法，它管理还在排队等待的Apps资源的分配，这个方法是每次在集群资源发生变动的时候都会调用，根据当前集群最新的资源来进行Apps的资源分配。</p>

<p><strong>Driver资源调度：</strong></p>

<p>随机的将Driver分配到空闲的Worker上去，详细流程请看我写的注释 ：）</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// First schedule drivers, they take strict precedence over applications  </span>
<span class="k">val</span> <span class="n">shuffledWorkers</span> <span class="k">=</span> <span class="nc">Random</span><span class="o">.</span><span class="n">shuffle</span><span class="o">(</span><span class="n">workers</span><span class="o">)</span> <span class="c1">// 把当前workers这个HashSet的顺序随机打乱  </span>
<span class="k">for</span> <span class="o">(</span><span class="n">worker</span> <span class="k">&lt;-</span> <span class="n">shuffledWorkers</span> <span class="k">if</span> <span class="n">worker</span><span class="o">.</span><span class="n">state</span> <span class="o">==</span> <span class="nc">WorkerState</span><span class="o">.</span><span class="nc">ALIVE</span><span class="o">)</span> <span class="o">{</span> <span class="c1">//遍历活着的workers  </span>
  <span class="k">for</span> <span class="o">(</span><span class="n">driver</span> <span class="k">&lt;-</span> <span class="n">waitingDrivers</span><span class="o">)</span> <span class="o">{</span> <span class="c1">//在等待队列中的Driver们会进行资源分配  </span>
    <span class="k">if</span> <span class="o">(</span><span class="n">worker</span><span class="o">.</span><span class="n">memoryFree</span> <span class="o">&gt;=</span> <span class="n">driver</span><span class="o">.</span><span class="n">desc</span><span class="o">.</span><span class="n">mem</span> <span class="o">&amp;&amp;</span> <span class="n">worker</span><span class="o">.</span><span class="n">coresFree</span> <span class="o">&gt;=</span> <span class="n">driver</span><span class="o">.</span><span class="n">desc</span><span class="o">.</span><span class="n">cores</span><span class="o">)</span> <span class="o">{</span> <span class="c1">//当前的worker内存和cpu均大于当前driver请求的mem和cpu，则启动  </span>
      <span class="n">launchDriver</span><span class="o">(</span><span class="n">worker</span><span class="o">,</span> <span class="n">driver</span><span class="o">)</span> <span class="c1">//启动Driver 内部实现是发送启动Driver命令给指定Worker，Worker来启动Driver。  </span>
      <span class="n">waitingDrivers</span> <span class="o">-=</span> <span class="n">driver</span> <span class="c1">//把启动过的Driver从队列移除  </span>
    <span class="o">}</span>  
  <span class="o">}</span>  
<span class="o">}</span>  
</code></pre></div>
<p><strong>Executor资源调度：</strong></p>

<p>Spark默认提供了一种在各个节点进行<code>round-robin</code>的调度，用户可以自己设置这个flag</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">spreadOutApps</span> <span class="k">=</span> <span class="n">conf</span><span class="o">.</span><span class="n">getBoolean</span><span class="o">(</span><span class="s">&quot;spark.deploy.spreadOut&quot;</span><span class="o">,</span> <span class="kc">true</span><span class="o">)</span>  
</code></pre></div>
<p>在介绍之前我们先介绍一个概念，
<code>可用的Worker</code>：什么是可用，可用就是资源空闲足够且满足一定的规则来启动当前App的Executor。</p>

<p>Spark定义了一个canUse方法：这个方法接受一个ApplicationInfo的描述信息和当前Worker的描述信息。
1. 当前worker的空闲内存 比 该app在每个slave要占用的内存 （executor.memory默认512M）大 
2. 当前app从未在此worker启动过App</p>

<p><strong>总结</strong>： 从这点看出，要满足：该Worker的当前可用最小内存要比配置的executor内存大，并且对于同一个App只能在一个Worker里启动一个Exeutor，如果要启动第二个Executor，那么请到其它Worker里。这样的才算是对App可用的Worker。</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="cm">/** </span>
<span class="cm"> * Can an app use the given worker? True if the worker has enough memory and we haven&#39;t already </span>
<span class="cm"> * launched an executor for the app on it (right now the standalone backend doesn&#39;t like having </span>
<span class="cm"> * two executors on the same worker). </span>
<span class="cm"> */</span>  
<span class="k">def</span> <span class="n">canUse</span><span class="o">(</span><span class="n">app</span><span class="k">:</span> <span class="kt">ApplicationInfo</span><span class="o">,</span> <span class="n">worker</span><span class="k">:</span> <span class="kt">WorkerInfo</span><span class="o">)</span><span class="k">:</span> <span class="kt">Boolean</span> <span class="o">=</span> <span class="o">{</span>  
  <span class="n">worker</span><span class="o">.</span><span class="n">memoryFree</span> <span class="o">&gt;=</span> <span class="n">app</span><span class="o">.</span><span class="n">desc</span><span class="o">.</span><span class="n">memoryPerSlave</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">worker</span><span class="o">.</span><span class="n">hasExecutor</span><span class="o">(</span><span class="n">app</span><span class="o">)</span>  
<span class="o">}</span>  
</code></pre></div>
<p><strong>SpreadOut分配策略：</strong></p>

<p>SpreadOut分配策略是一种以round-robin方式遍历集群所有可用Worker，分配Worker资源，来启动创建Executor的策略，好处是尽可能的将cores分配到各个节点，最大化负载均衡和高并行。
下面看看，默认的spreadOutApps模式启动App的过程： </p>

<ol>
<li>等待分配资源的apps队列默认是FIFO的。</li>
<li>app.coresLeft表示的是该app还有cpu资源没申请到：  app.coresLeft  = 当前app申请的maxcpus - granted的cpus</li>
<li>遍历未分配完全的apps，继续给它们分配资源，</li>
<li>usableWorkers =  从当前ALIVE的Workers中过滤找出上文描述的可用Worker，然后根据cpus的资源空闲，从大到小给Workers排序。</li>
<li>当toAssign（即将要分配的的core数&gt;0，就找到可以的Worker持续分配）</li>
<li>当可用Worker的free cores 大于 目前该Worker已经分配的core时，再给它分配1个core，这样分配是很平均的方法。</li>
<li>round-robin轮询可用的Worker循环</li>
<li>toAssign=0时结束循环，开始根据分配策略去真正的启动Executor。</li>
</ol>

<p>_<em>举例： _</em></p>

<p>1个APP申请了6个core, 现在有2个Worker可用。
那么： <code>toAssign = 6，assigned = 2</code>
那么就会在assigned(1)和assigned(0)中轮询平均分配cores，以+1 core的方式，最终每个Worker分到3个core，即每个Worker的启动一个Executor，每个Executor获得3个cores。</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// Right now this is a very simple FIFO scheduler. We keep trying to fit in the first app  </span>
    <span class="c1">// in the queue, then the second app, etc.  </span>
    <span class="k">if</span> <span class="o">(</span><span class="n">spreadOutApps</span><span class="o">)</span> <span class="o">{</span>  
      <span class="c1">// Try to spread out each app among all the nodes, until it has all its cores  </span>
      <span class="k">for</span> <span class="o">(</span><span class="n">app</span> <span class="k">&lt;-</span> <span class="n">waitingApps</span> <span class="k">if</span> <span class="n">app</span><span class="o">.</span><span class="n">coresLeft</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span> <span class="c1">//对还未被完全分配资源的apps处理  </span>
        <span class="k">val</span> <span class="n">usableWorkers</span> <span class="k">=</span> <span class="n">workers</span><span class="o">.</span><span class="n">toArray</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">state</span> <span class="o">==</span> <span class="nc">WorkerState</span><span class="o">.</span><span class="nc">ALIVE</span><span class="o">)</span>  
          <span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">canUse</span><span class="o">(</span><span class="n">app</span><span class="o">,</span> <span class="k">_</span><span class="o">)).</span><span class="n">sortBy</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">coresFree</span><span class="o">).</span><span class="n">reverse</span> <span class="c1">//根据core Free对可用Worker进行降序排序。  </span>
        <span class="k">val</span> <span class="n">numUsable</span> <span class="k">=</span> <span class="n">usableWorkers</span><span class="o">.</span><span class="n">length</span> <span class="c1">//可用worker的个数 eg:可用5个worker  </span>
        <span class="k">val</span> <span class="n">assigned</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Array</span><span class="o">[</span><span class="kt">Int</span><span class="o">](</span><span class="n">numUsable</span><span class="o">)</span> <span class="c1">//候选Worker，每个Worker一个下标，是一个数组，初始化默认都是0  </span>
        <span class="k">var</span> <span class="n">toAssign</span> <span class="k">=</span> <span class="n">math</span><span class="o">.</span><span class="n">min</span><span class="o">(</span><span class="n">app</span><span class="o">.</span><span class="n">coresLeft</span><span class="o">,</span> <span class="n">usableWorkers</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">coresFree</span><span class="o">).</span><span class="n">sum</span><span class="o">)</span><span class="c1">//还要分配的cores = 集群中可用Worker的可用cores总和（10）， 当前未分配core（5）中找最小的  </span>
        <span class="k">var</span> <span class="n">pos</span> <span class="k">=</span> <span class="mi">0</span>  
        <span class="k">while</span> <span class="o">(</span><span class="n">toAssign</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span>   
          <span class="k">if</span> <span class="o">(</span><span class="n">usableWorkers</span><span class="o">(</span><span class="n">pos</span><span class="o">).</span><span class="n">coresFree</span> <span class="o">-</span> <span class="n">assigned</span><span class="o">(</span><span class="n">pos</span><span class="o">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span> <span class="c1">//以round robin方式在所有可用Worker里判断当前worker空闲cpu是否大于当前数组已经分配core值  </span>
            <span class="n">toAssign</span> <span class="o">-=</span> <span class="mi">1</span>  
            <span class="n">assigned</span><span class="o">(</span><span class="n">pos</span><span class="o">)</span> <span class="o">+=</span> <span class="mi">1</span> <span class="c1">//当前下标pos的Worker分配1个core +1  </span>
          <span class="o">}</span>  
          <span class="n">pos</span> <span class="k">=</span> <span class="o">(</span><span class="n">pos</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span> <span class="o">%</span> <span class="n">numUsable</span> <span class="c1">//round-robin轮询寻找有资源的Worker  </span>
        <span class="o">}</span>  
        <span class="c1">// Now that we&#39;ve decided how many cores to give on each node, let&#39;s actually give them  </span>
        <span class="k">for</span> <span class="o">(</span><span class="n">pos</span> <span class="k">&lt;-</span> <span class="mi">0</span> <span class="n">until</span> <span class="n">numUsable</span><span class="o">)</span> <span class="o">{</span>  
          <span class="k">if</span> <span class="o">(</span><span class="n">assigned</span><span class="o">(</span><span class="n">pos</span><span class="o">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span> <span class="c1">//如果assigned数组中的值&gt;0，将启动一个executor在，指定下标的机器上。  </span>
            <span class="k">val</span> <span class="n">exec</span> <span class="k">=</span> <span class="n">app</span><span class="o">.</span><span class="n">addExecutor</span><span class="o">(</span><span class="n">usableWorkers</span><span class="o">(</span><span class="n">pos</span><span class="o">),</span> <span class="n">assigned</span><span class="o">(</span><span class="n">pos</span><span class="o">))</span> <span class="c1">//更新app里的Executor信息  </span>
            <span class="n">launchExecutor</span><span class="o">(</span><span class="n">usableWorkers</span><span class="o">(</span><span class="n">pos</span><span class="o">),</span> <span class="n">exec</span><span class="o">)</span>  <span class="c1">//通知可用Worker去启动Executor  </span>
            <span class="n">app</span><span class="o">.</span><span class="n">state</span> <span class="k">=</span> <span class="nc">ApplicationState</span><span class="o">.</span><span class="nc">RUNNING</span>  
          <span class="o">}</span>  
        <span class="o">}</span>  
      <span class="o">}</span>  
    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>  
</code></pre></div>
<p><strong>非SpreadOut分配策略：</strong></p>

<p>非SpreadOut策略，该策略：会尽可能的根据每个Worker的剩余资源来启动Executor，这样启动的Executor可能只在集群的一小部分机器的Worker上。这样做对node较少的集群还可以，集群规模大了，Executor的并行度和机器负载均衡就不能够保证了。</p>

<p>当用户设定了参数spark.deploy.spreadOut 为false时，触发此游戏分支偷笑，跑个题，有些困了。。
1. 遍历可用Workers
2. 且遍历Apps
3. 比较当前Worker的可用core和app还需要分配的core，取最小值当做还需要分配的core
4. 如果coreToUse大于0，则直接拿可用的core来启动Executor。。奉献当前Worker全部资源。（Ps：挨个榨干每个Worker的剩余资源。。。。）</p>

<p><strong>举例</strong>： App申请12个core，3个Worker，Worker1剩余1个core, Worke2r剩7个core, Worker3剩余4个core.</p>

<p>这样会启动3个Executor，Executor1 占用1个core, Executor2占用7个core, Executor3占用4个core.
<strong>总结</strong>：这样是尽可能的满足App，让其尽快执行，而忽略了其并行效率和负载均衡。</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="o">}</span> <span class="k">else</span> <span class="o">{</span>  
     <span class="c1">// Pack each app into as few nodes as possible until we&#39;ve assigned all its cores  </span>
     <span class="k">for</span> <span class="o">(</span><span class="n">worker</span> <span class="k">&lt;-</span> <span class="n">workers</span> <span class="k">if</span> <span class="n">worker</span><span class="o">.</span><span class="n">coresFree</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">worker</span><span class="o">.</span><span class="n">state</span> <span class="o">==</span> <span class="nc">WorkerState</span><span class="o">.</span><span class="nc">ALIVE</span><span class="o">)</span> <span class="o">{</span>  
       <span class="k">for</span> <span class="o">(</span><span class="n">app</span> <span class="k">&lt;-</span> <span class="n">waitingApps</span> <span class="k">if</span> <span class="n">app</span><span class="o">.</span><span class="n">coresLeft</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span>  
         <span class="k">if</span> <span class="o">(</span><span class="n">canUse</span><span class="o">(</span><span class="n">app</span><span class="o">,</span> <span class="n">worker</span><span class="o">))</span> <span class="o">{</span> <span class="c1">//直接问当前worker是有空闲的core  </span>
           <span class="k">val</span> <span class="n">coresToUse</span> <span class="k">=</span> <span class="n">math</span><span class="o">.</span><span class="n">min</span><span class="o">(</span><span class="n">worker</span><span class="o">.</span><span class="n">coresFree</span><span class="o">,</span> <span class="n">app</span><span class="o">.</span><span class="n">coresLeft</span><span class="o">)</span> <span class="c1">//有则取，不管多少  </span>
           <span class="k">if</span> <span class="o">(</span><span class="n">coresToUse</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span> <span class="c1">//有  </span>
             <span class="k">val</span> <span class="n">exec</span> <span class="k">=</span> <span class="n">app</span><span class="o">.</span><span class="n">addExecutor</span><span class="o">(</span><span class="n">worker</span><span class="o">,</span> <span class="n">coresToUse</span><span class="o">)</span> <span class="c1">//直接启动  </span>
             <span class="n">launchExecutor</span><span class="o">(</span><span class="n">worker</span><span class="o">,</span> <span class="n">exec</span><span class="o">)</span>  
             <span class="n">app</span><span class="o">.</span><span class="n">state</span> <span class="k">=</span> <span class="nc">ApplicationState</span><span class="o">.</span><span class="nc">RUNNING</span>  
           <span class="o">}</span>  
         <span class="o">}</span>  
       <span class="o">}</span>  
     <span class="o">}</span>  
   <span class="o">}</span>  
 <span class="o">}</span>  
</code></pre></div>
<h2>三、总结：</h2>

<ol>
<li>在Worker Actor中，每次LaunchExecutor会创建一个CoarseGrainedExecutorBackend进程，一个Executor对应一个CoarseGrainedExecutorBackend</li>
<li>针对同一个App，每个Worker里只能有一个针对该App的Executor存在，切记。如果想让整个App的Executor变多，设置SPARK<em>WORKER</em>INSTANCES，让Worker变多。</li>
<li>Executor的资源分配有2种策略：
3.1. SpreadOut ：一种以round-robin方式遍历集群所有可用Worker，分配Worker资源，来启动创建Executor的策略，好处是尽可能的将cores分配到各个节点，最大化负载均衡和高并行。
3.2. 非SpreadOut：会尽可能的根据每个Worker的剩余资源来启动Executor，这样启动的Executor可能只在集群的一小部分机器的Worker上。这样做对node较少的集群还可以，集群规模大了，Executor的并行度和机器负载均衡就不能够保证了。</li>
</ol>

<p>行文仓促，如有不正之处，请指出，欢迎讨论 ：）</p>

<h2>补充：</h2>

<p>1、关于： &nbsp;<span style="color:rgb(51,51,51); line-height:21px; background-color:rgb(242,242,242)">&nbsp;一个App一个Worker为什么只有允许有针对该App的一个Executor 到底这样设计为何？ 的讨论：</span></p>

<p><a target="_blank" target="_blank" href="http://weibo.com/lianchengzju" title="连城404" style="text-decoration:none; color:rgb(60,166,230); line-height:21px; background-color:rgb(250,250,250)">连城404</a><span style="color:rgb(51,51,51); line-height:21px; background-color:rgb(250,250,250)">：Spark是线程级并行模型，为什么需要一个worker为一个app启动多个executor呢？</span><br>
</p>

<p><a target="_blank" target="_blank" href="http://weibo.com/u/3324607202">朴动_zju</a>:一个worker对应一个executorbackend是从mesos那一套迁移过来的，mesos下也是一个slave一个executorbackend。我理解这里是可以实现起多个，但起多个貌&#20284;没什么好处，而且增加了复杂度。<br>
</p>

<p><span style="color:rgb(51,51,51); line-height:21px; background-color:rgb(250,250,250)"><a target="_blank" target="_blank" href="http://weibo.com/crazyjvm" style="line-height:21px; text-decoration:none; color:rgb(10,140,210); background-color:rgb(250,250,250)">CrazyJvm</a><a target="_blank" target="_blank" href="http://club.weibo.com/intro" style="line-height:21px; text-decoration:none; color:rgb(10,140,210); background-color:rgb(250,250,250)"><span title="微博达人" class="W_ico16 ico_club" style="display:inline-block; width:14px; height:14px; margin-left:2px; vertical-align:text-bottom"></span></a><a target="_blank" target="_blank" title="微博会员" href="http://vip.weibo.com/personal?from=main" style="line-height:21px; text-decoration:none; color:rgb(10,140,210); background-color:rgb(250,250,250)"><span class="W_ico16 ico_member5" style="display:inline-block; width:16px; height:14px; margin-left:2px; vertical-align:text-bottom"></span></a><span style="line-height:21px; color:rgb(51,51,51); background-color:rgb(250,250,250)">：</span><a target="_blank" target="_blank" href="http://weibo.com/n/CodingCat" style="line-height:21px; text-decoration:none; color:rgb(10,140,210); background-color:rgb(250,250,250)">@CodingCat</a><span style="line-height:21px; color:rgb(51,51,51); background-color:rgb(250,250,250)">&nbsp;做了一个patch可以启动多个，但是还没有被merge。
 从Yarn的角度考虑的话，一个Worker可以对应多个executorbackend，正如一个nodemanager对应多个container。&nbsp;</span><a target="_blank" target="_blank" href="http://weibo.com/n/OopsOutOfMemory" style="line-height:21px; text-decoration:none; color:rgb(10,140,210); background-color:rgb(250,250,250)">@OopsOutOfMemory</a><span style="line-height:21px; color:rgb(51,51,51); background-color:rgb(250,250,250)">&nbsp;</span><br>
</span></p>
<p><span style="color:rgb(51,51,51); line-height:21px; background-color:rgb(250,250,250)"><a target="_blank" target="_blank" href="http://weibo.com/oopsoom" title="OopsOutOfMemory" style="text-decoration:none; color:rgb(60,166,230); line-height:21px; background-color:rgb(250,250,250)">OopsOutOfMemory</a><a target="_blank" target="_blank" href="http://club.weibo.com/intro" style="text-decoration:none; color:rgb(60,166,230); line-height:21px; background-color:rgb(250,250,250)"><span title="微博达人" class="W_ico16 ico_club" style="display:inline-block; width:14px; height:14px; margin-left:2px; vertical-align:text-bottom"></span></a><span style="color:rgb(51,51,51); line-height:21px; background-color:rgb(250,250,250)">：回复</span><a target="_blank" target="_blank" href="http://weibo.com/n/%E8%BF%9E%E5%9F%8E404" style="text-decoration:none; color:rgb(60,166,230); line-height:21px; background-color:rgb(250,250,250)">@连城404</a><span style="color:rgb(51,51,51); line-height:21px; background-color:rgb(250,250,250)">:
 如果一个executor太大且装的对象太多，会导致GC很慢，多几个Executor会减少full gc慢的问题。 see this post&nbsp;</span><a target="_blank" target="_blank" title="http://apache-spark-user-list.1001560.n3.nabble.com/executor-cores-vs-num-executors-td9878.html" href="http://t.cn/RP1bVO4" style="text-decoration:none; color:rgb(60,166,230); line-height:21px; background-color:rgb(250,250,250)">http://t.cn/RP1bVO4</a><span style="color:rgb(51,51,51); line-height:21px; background-color:rgb(250,250,250)"></span><span class="S_txt2" style="color:rgb(128,128,128); line-height:21px; background-color:rgb(250,250,250)">(今天
 11:25)</span><br>
</span></p>
<p><span style="color:rgb(51,51,51); line-height:21px; background-color:rgb(250,250,250)"><span class="S_txt2" style="color:rgb(128,128,128); line-height:21px; background-color:rgb(250,250,250)"><a target="_blank" target="_blank" href="http://weibo.com/lianchengzju" title="连城404" style="text-decoration:none; color:rgb(60,166,230); line-height:21px; background-color:rgb(250,250,250)">连城404</a><span style="color:rgb(51,51,51); line-height:21px; background-color:rgb(250,250,250)">：回复</span><a target="_blank" target="_blank" href="http://weibo.com/n/OopsOutOfMemory" style="text-decoration:none; color:rgb(60,166,230); line-height:21px; background-color:rgb(250,250,250)">@OopsOutOfMemory</a><span style="color:rgb(51,51,51); line-height:21px; background-color:rgb(250,250,250)">:哦，这个考虑是有道理的。一个workaround是单台机器部署多个worker，worker相对来说比较廉价。&nbsp;</span></span></span></p>
<p><span style="color:rgb(51,51,51); line-height:21px; background-color:rgb(250,250,250)"><span class="S_txt2" style="color:rgb(128,128,128); line-height:21px; background-color:rgb(250,250,250)"><span style="color:rgb(51,51,51); line-height:21px; background-color:rgb(250,250,250)"><a target="_blank" target="_blank" href="http://weibo.com/jerrylead" style="text-decoration:none; color:rgb(10,140,210); line-height:21px; background-color:rgb(250,250,250)">JerryLead</a><span style="color:rgb(51,51,51); line-height:21px; background-color:rgb(250,250,250)">：回复</span><a target="_blank" target="_blank" href="http://weibo.com/n/OopsOutOfMemory" style="text-decoration:none; color:rgb(10,140,210); line-height:21px; background-color:rgb(250,250,250)">@OopsOutOfMemory</a><span style="color:rgb(51,51,51); line-height:21px; background-color:rgb(250,250,250)">:看来都还在变化当中，standalone
 和 YARN 还是有很多不同，我们暂不下结论 (今天 11:35)</span></span></span></span></p>
<p><a target="_blank" target="_blank" href="http://weibo.com/jerrylead" title="JerryLead" style="text-decoration:none; color:rgb(60,166,230); line-height:21px; background-color:rgb(250,250,250)">JerryLead</a><span style="color:rgb(51,51,51); line-height:21px; background-color:rgb(250,250,250)">：问题开始变得复杂了，是提高线程并行度还是提高进程并行度？我想
 Spark 还是优先选择前者，这样 task 好管理，而且 broadcast，cache 的效率高些。后者有一些道理，但参数配置会变得更复杂，各有利弊吧 </span>
<span class="S_txt2" style="color:rgb(128,128,128); line-height:21px; background-color:rgb(250,250,250)">(今天 11:40)</span></p>
<p><br>
</p>

<p>未完待续。。。</p>

<p>传送门：@JerrLead &nbsp;<a target="_blank" href="https://github.com/JerryLead/SparkInternals/blob/master/markdown/1-Overview.md">https://github.com/JerryLead/SparkInternals/blob/master/markdown/1-Overview.md</a></p>

<p><br>
</p>

		<h5>(The End)</h5>
		<h5><原创文章> From OopsOutOfMemory 盛利's Blog<h5>
		<h5>转载请注明出自：<a href="http://oopsoutofmemory.github.io/spark/2014/11/19/spark-executor-driver-zi-yuan-diao-du-xiao-jie"> http://oopsoutofmemory.github.io/spark/2014/11/19/spark-executor-driver-zi-yuan-diao-du-xiao-jie</a></h5>
	

<div class="ds-thread"></div>  
	</div>



</div>


	
	
	
	
	
	


<footer class="clean" style="background-image: url(/assets/images/cover.jpg); height: 75%; min-height: 500px;" data-stellar-background-ratio="0.5" data-stellar-horizontal-offset="50" data-stellar-vertical-offset="50">
	<div id="nav-icon" style="top: 60px;" data-stellar-ratio="0.8">
		<a class="scroll" data-speed="500" href="#article"><span class="genericon genericon-collapse"></span></a>
	</div>
	<div id="post-info" data-stellar-ratio="0.5" data-stellar-vertical-offset="120">
		<h3>下一篇文章：</h3>
		<a href="/machine%20learning/spark/mllib/2014/11/19/spark-ji-qi-xue-xi-ku-mllib-zhi-xie-tong-guo-lv">
			<h1>Spark机器学习库mllib之协同过滤</h1>
			
				<h2></h2>
			
		</a>
	</div>


	<p class="copyright">&copy;2015, <a href="http://oopsoutofmemory.github.io" target="_blank">盛利</a>. <a href="http://oopsoutofmemory.github.io" target="_blank">All rights reserved</a>.</p>
</footer>
<script src="/assets/js/smooth-scroll.js"></script>



		<script>
		var width = $(window).width()
		if ( width > 899 )
		$( function(){
		    $.stellar({
		    	responsive: true,
			verticalScrolling: true,
			horizontalOffset: 0,
			verticalOffset: 0,
			positionProperty: 'transform',
		    });
		});
		</script>
	</body>
</html>
 <!--多说js加载开始，一个页面只需要加载一次 -->
    <script type="text/javascript">
      var duoshuoQuery = {short_name:"oopsoutofmemory"};
      (function() {
        var ds = document.createElement('script');
        ds.type = 'text/javascript';ds.async = true;
        ds.src = 'http://static.duoshuo.com/embed.js';
        ds.charset = 'UTF-8';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(ds);
      })();
    </script>
    <!--多说js加载结束，一个页面只需要加载一次 -->

 